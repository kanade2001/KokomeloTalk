{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdMUbYUSmEEQIyZjdnXXlc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanade2001/KokomeloTalk/blob/g0roro%2Festimate_emotion/backend/public_emotion_estimate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なモジュールのインストール/インポート\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "! pip install fugashi ipadic\n",
        "! pip install unidic_lite\n",
        "import numpy as np\n",
        "import os\n",
        "import gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u_x7sn8Stl1",
        "outputId": "d1b9208d-76c7-4ebc-b006-d0304034b46c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fugashi\n",
            "  Downloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.7/671.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=fb8ec0da78ba49ce11c880b552d67eee920db29d9a296817424ff26bdc870e2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic, fugashi\n",
            "Successfully installed fugashi-1.4.0 ipadic-1.0.0\n",
            "Collecting unidic_lite\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unidic_lite\n",
            "  Building wheel for unidic_lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic_lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=7e038e4e4b5cdd10392ba798f3b568ec48f202a952d7d44dbffd48784ddaf562\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "Successfully built unidic_lite\n",
            "Installing collected packages: unidic_lite\n",
            "Successfully installed unidic_lite-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "isTb3eP1JwNF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj1lnLmHSVqU",
        "outputId": "e2929e50-946e-4fc3-8e47-2eb7248dda2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1-2LeATWCSnzrmj94qXuXNy2Kkg1dWYRM config.json\n",
            "Processing file 1-4v4SmOZpP9qptoIRGtA9HxviXk3loG3 model.safetensors\n",
            "Processing file 1-6ZRfqGyU5tvVfMLVz09lY6zACI0TZsX special_tokens_map.json\n",
            "Processing file 1-FXYSX3WHD7odmWW7kgSJS0q4XVCA0Dc tokenizer_config.json\n",
            "Processing file 1-604zi6s3vEQ7bOM8B8tAbKhXJWpDP0A vocab.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2LeATWCSnzrmj94qXuXNy2Kkg1dWYRM\n",
            "To: /content/trained_model/config.json\n",
            "100%|██████████| 1.11k/1.11k [00:00<00:00, 2.99MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-4v4SmOZpP9qptoIRGtA9HxviXk3loG3\n",
            "From (redirected): https://drive.google.com/uc?id=1-4v4SmOZpP9qptoIRGtA9HxviXk3loG3&confirm=t&uuid=3dfb03df-86cb-4f86-98c8-3595305b614f\n",
            "To: /content/trained_model/model.safetensors\n",
            "100%|██████████| 443M/443M [00:03<00:00, 113MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-6ZRfqGyU5tvVfMLVz09lY6zACI0TZsX\n",
            "To: /content/trained_model/special_tokens_map.json\n",
            "100%|██████████| 125/125 [00:00<00:00, 327kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-FXYSX3WHD7odmWW7kgSJS0q4XVCA0Dc\n",
            "To: /content/trained_model/tokenizer_config.json\n",
            "100%|██████████| 1.37k/1.37k [00:00<00:00, 3.95MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-604zi6s3vEQ7bOM8B8tAbKhXJWpDP0A\n",
            "To: /content/trained_model/vocab.txt\n",
            "100%|██████████| 258k/258k [00:00<00:00, 68.9MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/trained_model/config.json',\n",
              " '/content/trained_model/model.safetensors',\n",
              " '/content/trained_model/special_tokens_map.json',\n",
              " '/content/trained_model/tokenizer_config.json',\n",
              " '/content/trained_model/vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# フォルダIDを指定\n",
        "folder_id = \"1YmF_3TihtXOEELXUr_ShG1kT4rIIzgef\"\n",
        "\n",
        "# ダウンロード先ディレクトリ\n",
        "save_dir = \"/content/trained_model\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# gdownを使ってフォルダ全体をダウンロード\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=save_dir, quiet=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルとトークナイザを読み込み\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "\n",
        "# デバイスを指定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf7n6pWqSrt3",
        "outputId": "cc65e0ce-21ff-4e1b-d0a0-55115eff0aa7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 感情名（日本語）を定義\n",
        "emotion_names_jp = ['喜び', '悲しみ', '怒り', '恐れ', '嫌悪', '驚き', '信頼', '期待'] # 例として8つの感情を想定\n",
        "\n",
        "# ソフトマックス関数\n",
        "def np_softmax(x):\n",
        "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "    return f_x\n",
        "\n",
        "def analyze_emotion(text):\n",
        "    # 推論モードを有効化\n",
        "    loaded_model.eval()\n",
        "\n",
        "    # 入力データ変換 + 推論\n",
        "    tokens = loaded_tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
        "    tokens.to(loaded_model.device)\n",
        "    preds = loaded_model(**tokens)\n",
        "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
        "    out_dict = {n: p for n, p in zip(emotion_names_jp, prob)}\n",
        "    out_dict_ud = sorted(out_dict.items(), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "    print(\"入力文：\", text)\n",
        "    print(out_dict_ud)\n",
        "\n",
        "analyze_emotion('昨日彼女に振られました')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biWDa9keS7GO",
        "outputId": "0cfaa663-87f8-426d-ff19-1bf0cf2bf449"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力文： 昨日彼女に振られました\n",
            "[('悲しみ', 0.9329988), ('信頼', 0.039915565), ('驚き', 0.01132242), ('恐れ', 0.00851324), ('喜び', 0.003976579), ('嫌悪', 0.002052537), ('怒り', 0.0010010423), ('期待', 0.0002198929)]\n"
          ]
        }
      ]
    }
  ]
}